{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ddsp\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import ddsp.training\n",
    "import librosa\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "import time\n",
    "import gin\n",
    "sample_rate = 16000\n",
    "from ddsp.training.postprocessing import (\n",
    "    detect_notes, fit_quantile_transform\n",
    ")\n",
    "\n",
    "from ddsp.colab.colab_utils import (\n",
    "    auto_tune, get_tuning_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "track = AudioSegment.from_file(\"./data/test_trumpet.m4a\", format=\"m4a\")\n",
    "file_handle = track.export(\"test_trumpet.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_audio, samp_rate = sf.read(\"./data/test_trumpy.wav\")\n",
    "# print(\"SAMP:\", samp_rate)\n",
    "\n",
    "# test_audio = test_audio[np.newaxis, :]\n",
    "\n",
    "\n",
    "test_resamp, rate = librosa.load(\"./data/test_trumpet.wav\", sr=sample_rate)\n",
    "test_resamp = test_resamp[np.newaxis, :]\n",
    "\n",
    "\n",
    "ipd.Audio(test_resamp, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddsp.spectral_ops.reset_crepe()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "audio_features = ddsp.training.metrics.compute_audio_features(test_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each in audiofeatures.keys():\n",
    "    # print(each, features[each].shape)\n",
    "\n",
    "audio_features[\"loudness_db\"] = audio_features[\"loudness_db\"].numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIM = -15\n",
    "fig, ax = plt.subplots(nrows=3, \n",
    "                       ncols=1, \n",
    "                       sharex=True,\n",
    "                       figsize=(6, 8))\n",
    "ax[0].plot(audio_features['loudness_db'][:TRIM])\n",
    "ax[0].set_ylabel('loudness_db')\n",
    "\n",
    "ax[1].plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n",
    "ax[1].set_ylabel('f0 [midi]')\n",
    "\n",
    "ax[2].plot(audio_features['f0_confidence'][:TRIM])\n",
    "ax[2].set_ylabel('f0 confidence')\n",
    "_ = ax[2].set_xlabel('Time step [frame]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_dir = \"checkpoints/trumpet_pretrained/\"\n",
    "gin_file = os.path.join(model_dir, \"operative_config-0.gin\")\n",
    "print(gin_file)\n",
    "\n",
    "\n",
    "STATS = None\n",
    "stats_file = \"checkpoints/trumpet_pretrained/dataset_statistics.pkl\"\n",
    "try:\n",
    "    with open(stats_file, \"rb\") as f:\n",
    "        STATS = pickle.load(f)\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "\n",
    "\n",
    "\n",
    "with gin.unlock_config():\n",
    "    gin.parse_config_file(gin_file, skip_unknown=True)\n",
    "\n",
    "ckpt = \"./checkpoints/trumpet_pretrained/ckpt-20000.index\"\n",
    "\n",
    "time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
    "n_samples_train = gin.query_parameter('Harmonic.n_samples')\n",
    "hop_size = int(n_samples_train / time_steps_train)\n",
    "\n",
    "time_steps = int(test_resamp.shape[1] / hop_size)\n",
    "n_samples = time_steps * hop_size\n",
    "\n",
    "\n",
    "gin_params = [\n",
    "    'Harmonic.n_samples = {}'.format(n_samples),\n",
    "    'FilteredNoise.n_samples = {}'.format(n_samples),\n",
    "    'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
    "    'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
    "]\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_params)\n",
    "\n",
    "\n",
    "# Trim all input vectors to correct lengths \n",
    "for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
    "  audio_features[key] = audio_features[key][:time_steps]\n",
    "audio_features['audio'] = audio_features['audio'][:, :n_samples]\n",
    "\n",
    "\n",
    "\n",
    "model = ddsp.training.models.Autoencoder()\n",
    "model.restore(\"./checkpoints/trumpet_pretrained/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for each in audio_features.items():\n",
    "    print(each[0], type(each[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1 #@param {type:\"slider\", min: 0.0, max:2.0, step:0.01}\n",
    "ADJUST = True #@param{type:\"boolean\"}\n",
    "quiet = 20 #@param {type:\"slider\", min: 0, max:60, step:1}\n",
    "autotune = 0.0 #@param {type:\"slider\", min: 0.0, max:1.0, step:0.1}\n",
    "pitch_shift =  0 #@param {type:\"slider\", min:-2, max:2, step:1}\n",
    "loudness_shift = 2 #@param {type:\"slider\", min:-20, max:20, step:1}\n",
    "audio_features_mod = {k: v.copy() for k, v in audio_features.items()}\n",
    "\n",
    "\n",
    "def shift_ld(audio_features, ld_shift=0.0):\n",
    "  \"\"\"Shift loudness by a number of ocatves.\"\"\"\n",
    "  audio_features['loudness_db'] += ld_shift\n",
    "  return audio_features\n",
    "\n",
    "\n",
    "def shift_f0(audio_features, pitch_shift=0.0):\n",
    "  \"\"\"Shift f0 by a number of ocatves.\"\"\"\n",
    "  audio_features['f0_hz'] *= 2.0 ** (pitch_shift)\n",
    "  audio_features['f0_hz'] = np.clip(audio_features['f0_hz'], \n",
    "                                    0.0, \n",
    "                                    librosa.midi_to_hz(110.0))\n",
    "  return audio_features\n",
    "\n",
    "\n",
    "mask_on = None\n",
    "\n",
    "if ADJUST and STATS is not None:\n",
    "  # Detect sections that are \"on\".\n",
    "  mask_on, note_on_value = detect_notes(audio_features['loudness_db'],\n",
    "                                        audio_features['f0_confidence'],\n",
    "                                        threshold)\n",
    "\n",
    "  if np.any(mask_on):\n",
    "    # Shift the pitch register.\n",
    "    target_mean_pitch = STATS['mean_pitch']\n",
    "    pitch = ddsp.core.hz_to_midi(audio_features['f0_hz'])\n",
    "    mean_pitch = np.mean(pitch[mask_on])\n",
    "    p_diff = target_mean_pitch - mean_pitch\n",
    "    p_diff_octave = p_diff / 12.0\n",
    "    round_fn = np.floor if p_diff_octave > 1.5 else np.ceil\n",
    "    p_diff_octave = round_fn(p_diff_octave)\n",
    "    audio_features_mod = shift_f0(audio_features_mod, p_diff_octave)\n",
    "\n",
    "\n",
    "    # Quantile shift the note_on parts.\n",
    "    _, loudness_norm = fit_quantile_transform(\n",
    "        audio_features['loudness_db'],\n",
    "        mask_on,\n",
    "        inv_quantile=STATS['quantile_transform'])\n",
    "\n",
    "    # Turn down the note_off parts.\n",
    "    mask_off = np.logical_not(mask_on)\n",
    "    loudness_norm[mask_off] -=  quiet * (1.0 - note_on_value[mask_off][:, np.newaxis])\n",
    "    loudness_norm = np.reshape(loudness_norm, audio_features['loudness_db'].shape)\n",
    "    \n",
    "    audio_features_mod['loudness_db'] = loudness_norm \n",
    "\n",
    "    # Auto-tune.\n",
    "    if autotune:\n",
    "      f0_midi = np.array(ddsp.core.hz_to_midi(audio_features_mod['f0_hz']))\n",
    "      tuning_factor = get_tuning_factor(f0_midi, audio_features_mod['f0_confidence'], mask_on)\n",
    "      f0_midi_at = auto_tune(f0_midi, tuning_factor, mask_on, amount=autotune)\n",
    "      audio_features_mod['f0_hz'] = ddsp.core.midi_to_hz(f0_midi_at)\n",
    "\n",
    "  else:\n",
    "    print('\\nSkipping auto-adjust (no notes detected or ADJUST box empty).')\n",
    "\n",
    "else:\n",
    "  print('\\nSkipping auto-adujst (box not checked or no dataset statistics found).')\n",
    "\n",
    "# Manual Shifts.\n",
    "audio_features_mod = shift_ld(audio_features_mod, loudness_shift)\n",
    "audio_features_mod = shift_f0(audio_features_mod, pitch_shift)\n",
    "\n",
    "\n",
    "\n",
    "# Plot Features.\n",
    "has_mask = int(mask_on is not None)\n",
    "n_plots = 3 if has_mask else 2 \n",
    "fig, axes = plt.subplots(nrows=n_plots, \n",
    "                      ncols=1, \n",
    "                      sharex=True,\n",
    "                      figsize=(2*n_plots, 8))\n",
    "\n",
    "if has_mask:\n",
    "  ax = axes[0]\n",
    "  ax.plot(np.ones_like(mask_on[:TRIM]) * threshold, 'k:')\n",
    "  ax.plot(note_on_value[:TRIM])\n",
    "  ax.plot(mask_on[:TRIM])\n",
    "  ax.set_ylabel('Note-on Mask')\n",
    "  ax.set_xlabel('Time step [frame]')\n",
    "  ax.legend(['Threshold', 'Likelihood','Mask'])\n",
    "\n",
    "ax = axes[0 + has_mask]\n",
    "ax.plot(audio_features['loudness_db'][:TRIM])\n",
    "ax.plot(audio_features_mod['loudness_db'][:TRIM])\n",
    "ax.set_ylabel('loudness_db')\n",
    "ax.legend(['Original','Adjusted'])\n",
    "\n",
    "ax = axes[1 + has_mask]\n",
    "ax.plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n",
    "ax.plot(librosa.hz_to_midi(audio_features_mod['f0_hz'][:TRIM]))\n",
    "ax.set_ylabel('f0 [midi]')\n",
    "_ = ax.legend(['Original','Adjusted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(audio_features_mod, training=False)\n",
    "audio_gen = model.get_audio_from_outputs(out)\n",
    "\n",
    "ipd.Audio(audio_gen, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 0\n",
    "for each in range(1000):\n",
    "    if each%5 ==0 or each%3 == 0 :\n",
    "        out+=each\n",
    "print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
