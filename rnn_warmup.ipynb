{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unidecode\n",
    "all_chars = string.printable\n",
    "n_chars = len(all_chars)\n",
    "\n",
    "with open(\"names.txt\", \"r\") as f:\n",
    "\n",
    "    names = [each.lower().strip() for each in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_chars)\n",
    "print(all_chars.index(\"*\")) # use as pad character\n",
    "print(all_chars.index(\"$\")) # use as EOF character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [torch.Tensor([all_chars.index(char) for char in each] + [65]).long() for each in names]\n",
    "out = torch.nn.utils.rnn.pad_sequence(out, batch_first=True, padding_value= 71)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bob(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, n_layers,device):\n",
    "        super(Bob, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.embed = nn.Embedding(in_size, hidden_size, padding_idx=71)\n",
    "        torch.nn.init.xavier_uniform_(self.embed.weight)\n",
    "        # print(self.embed.weight.isnan().any())\n",
    "        # print(f\"Max {self.embed.weight.max()} Min {self.embed.weight.min()}\")\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, batch_first = True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(hidden_size, out_size)\n",
    "    def generate_sample(self,bs,len_gen, start=\"a\" ):\n",
    "        x = torch.zeros(bs, 1).long().to(self.device)\n",
    "        for ix in range(x.shape[0]):\n",
    "            x[ix] = all_chars.index(start)\n",
    "        out = [start for _ in range(bs)]\n",
    "        x, hidden, _ =  self.forward(x)\n",
    "        x = F.softmax(x, dim=2)\n",
    "        print(\"FIRST OUT\", x.shape, x.isnan().any())\n",
    "        preds = torch.argmax(x, dim=2)\n",
    "        print(\"FRIST PRED:\",preds.shape, preds.isnan().any())\n",
    "        # print(\"FIRST PRED:\", preds)\n",
    "        for ix, each in enumerate(out):\n",
    "            out[ix] += all_chars[preds[ix].item()]\n",
    "        for _ in range(len_gen-1):\n",
    "            x, hidden, _ = self.forward(preds, hidden)\n",
    "            x = F.softmax(x, dim=2)\n",
    "            hidden = hidden.detach()\n",
    "            print(\"OUT\",x.shape, preds.isnan().any())\n",
    "            preds = torch.argmax(x, dim=2)\n",
    "            print(\"PREDS:\",preds.shape, preds.isnan().any())\n",
    "            # print(preds)\n",
    "            x = preds\n",
    "            for ix, each in enumerate(out):\n",
    "                print(preds[ix].item())\n",
    "                out[ix] += all_chars[preds[ix].item()]\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        out = None\n",
    "        out = 0 if x.isnan().any() and out is None else out\n",
    "        # x = F.one_hot(x)\n",
    "        x = self.embed(x)\n",
    "        out = 1 if x.isnan().any() and out is None else out\n",
    "        # print(f\"AFTER EMBED: {x_e.isnan().any()}\")\n",
    "        # print(x_e[:1])\n",
    "        if hidden is None:\n",
    "            x, hidden = self.gru(x)\n",
    "        else:\n",
    "            x, hidden = self.gru(x, hidden)\n",
    "        \n",
    "        out = 2 if x.isnan().any() and out is None else out\n",
    "\n",
    "        # print(f\"AFTER GRU: {x.isnan().any()}\")\n",
    "\n",
    "        # print(x[:1])\n",
    "        x = self.relu(x)\n",
    "        out = 3 if x.isnan().any() and out is None else out\n",
    "\n",
    "        # print(f\"AFTER Leaky: {x.isnan().any()}\")\n",
    "\n",
    "        # print(x[:1])\n",
    "        x = self.out(x)\n",
    "        out = 4 if x.isnan().any() and out is None else out\n",
    "\n",
    "\n",
    "        # print(f\"AFTER FC: {x.isnan().any()}\")\n",
    "\n",
    "        # print(x[:1])\n",
    "        return x, hidden, out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, src):\n",
    "        self.src= src\n",
    "        self.tgt = torch.zeros_like(src)\n",
    "\n",
    "        self.tgt[:, :-1] = self.src[:, 1:]\n",
    "        self.tgt[:, -1] = 71.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.src[idx], self.tgt[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.anomaly_mode.set_detect_anomaly(True)\n",
    "customset = CustomDataset(out)\n",
    "loader = torch.utils.data.DataLoader(customset, batch_size=128, shuffle=True)\n",
    "device = torch.device(\"mps\")\n",
    "num_epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = Bob(n_chars, 256, n_chars, 2, device).to(device)\n",
    "model.train()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "first_nan = None\n",
    "nan_loss = None\n",
    "for ep in (pbar :=tqdm(range(num_epochs))):\n",
    "    for idx, (src, tgt) in enumerate(loader):\n",
    "        # print(idx)\n",
    "        if src.isnan().any():\n",
    "            ValueError(\"WTF BRO\")\n",
    "\n",
    "        optim.zero_grad()\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device).long()\n",
    "        # print(\"GRRR\",src.isnan().any())\n",
    "        preds, _, nanthrown = model(src)\n",
    "        has_nan = preds.isnan().any()\n",
    "        if has_nan:\n",
    "            print(\"FOUND NAN IN PREDS AT: {}\",str(ep) + \",\"+ str(idx))\n",
    "        first_nan = str(ep) + \",\"+ str(idx) if has_nan and first_nan is None else first_nan\n",
    "        loss = loss_fn(preds.permute(0,2,1), tgt)\n",
    "        # print(loss)\n",
    "\n",
    "        nan_loss = str(ep) + \",\"+ str(idx) if loss.isnan() and nan_loss is None else nan_loss\n",
    "        if nan_loss:\n",
    "            print(\"FOUND NAN IN lOSS AT: {}\",str(ep) + \",\"+ str(idx))\n",
    "\n",
    "        loss.backward()\n",
    "        for param in model.parameters():\n",
    "            torch.clamp(param, -1, 1)\n",
    "            pbar.set_description(f\"Last Loss: {loss.item() if idx > 0 else 0} {ep},{idx} {each.isnan().any().item(), each.isinf().any().item(), each.isneginf().any().item()}\")\n",
    "\n",
    "        optim.step()\n",
    "        # pbar.set_description(\"Ep: {} First Nan: {} Has Nan: {} Nan_loss: {} Where Thrown: {} Iter:{}/{} Loss: {}\".format(ep,first_nan, has_nan,nan_loss,nanthrown,idx,len(loader), loss))\n",
    "        # break\n",
    "    # break\n",
    "torch.save(model.state_dict(), \"weights.pth\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"weights.pth\"))\n",
    "model.eval()\n",
    "model.generate_sample(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
