{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/names.txt', \"r\") as f:\n",
    "    names = [each.lower().strip() for each in f.readlines()]\n",
    "\n",
    "all_chars=\"abcdefghijklmnopqrstuvwxyz*$\"\n",
    "n_chars = len(all_chars)\n",
    "data = [[all_chars.index(char) for char in each] for each in names]\n",
    "total_lens = [len(each) for each in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(all_chars.index(\"*\"))\n",
    "print(all_chars.index(\"$\"))\n",
    "\n",
    "data_tensors = torch.nn.utils.rnn.pad_sequence([torch.Tensor(each).int() for each in data], batch_first=True, padding_value=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, src, lens):\n",
    "        super(CustomDataset, self).__init__()\n",
    "\n",
    "        self.src = src\n",
    "        self.tgt = torch.zeros_like(src)\n",
    "        self.lens = lens\n",
    "\n",
    "        self.tgt[:,:-1] = self.src[:,1:]\n",
    "        self.tgt[:,-1] = 26\n",
    "\n",
    "        for ix, each in enumerate(self.lens):\n",
    "            self.tgt[ix, each-1] = 27\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.src[idx], self.lens[idx], self.tgt[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gen(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, lens, n_layers,dropout, device):\n",
    "        super(Gen, self).__init__()\n",
    "\n",
    "        self.num_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "\n",
    "        self.lens = lens\n",
    "        self.embed = nn.Embedding(in_size, hidden_size, padding_idx=26)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers, batch_first=True, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        h = torch.zeros(self.num_layers, bs, self.hidden_size).to(self.device)\n",
    "        c = torch.zeros(self.num_layers, bs, self.hidden_size).to(self.device)\n",
    "        return h,c\n",
    "    def forward (self, X,lens, h, c):\n",
    "        X = self.embed(X)\n",
    "        # print(\"IN\", X.shape)\n",
    "        if lens is not None:\n",
    "            X = torch.nn.utils.rnn.pack_padded_sequence(X, lens, batch_first=True, enforce_sorted=False)\n",
    "            X, (h, c )= self.lstm(X,( h, c))\n",
    "            X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True,total_length=15)\n",
    "        else:\n",
    "            X, (h,c) = self.lstm(X, (h,c))\n",
    "        # X = F.relu(X)\n",
    "\n",
    "        X = self.out(X)\n",
    "\n",
    "        return X,h,c\n",
    "    \n",
    "    def generate(self,start=\"a\", gen_len=7,temperature=0.85):\n",
    "\n",
    "        hidden, cell = self.init_hidden(1)\n",
    "        initial_input = torch.Tensor([all_chars.index(each) for each in start]).int().unsqueeze(0)\n",
    "        # print(initial_input.shape)\n",
    "        predicted = start\n",
    "\n",
    "        for p in range(len(start) - 1):\n",
    "            _, hidden, cell = self.forward(\n",
    "                initial_input[p].view(1).to(self.device),None, hidden, cell\n",
    "            )\n",
    "\n",
    "        last_char = initial_input[-1].unsqueeze(0)\n",
    "        # print(\"INITIAL LAST CHAR: \", last_char.shape)\n",
    "        # print(\"SHAPED\", last_char.view(1).shape)\n",
    "\n",
    "        for p in range(gen_len):\n",
    "            output, hidden, cell = self.forward(\n",
    "                last_char.to(self.device),None, hidden, cell\n",
    "            )\n",
    "            # print(\"OUTPUTSHAPE\",output.shape)\n",
    "            output_dist = F.softmax(output, dim=2).squeeze(1)\n",
    "            # print(\"OUDIST\", output_dist.shape)\n",
    "            top_char = torch.multinomial(output_dist, 1)[0]\n",
    "            # print(\"TOP\",top_char)\n",
    "            predicted_char = all_chars[top_char]\n",
    "            # print(predicted_char)\n",
    "            predicted += predicted_char\n",
    "            last_char = torch.Tensor([all_chars.index(predicted_char)]).int().unsqueeze(0)\n",
    "            # print(\"LAST\",last_char.shape, last_char)\n",
    "\n",
    "        return predicted\n",
    "     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "dataset = CustomDataset(data_tensors, total_lens)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30:44/143 Loss:2.658299684524536:  50%|█████     | 10/20 [17:07<16:39, 99.97s/it]  /Users/doriclink/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:173: UserWarning: Error detected in MpsLinearBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/5k/kckt_jmd1_xbj20fhpwwv65w0000gn/T/ipykernel_72104/758398684.py\", line 21, in <module>\n",
      "    preds, h, c = model(src, lens, h, c)\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    if a single value is returned(unless that value is already a tuple).\n",
      "  File \"/var/folders/5k/kckt_jmd1_xbj20fhpwwv65w0000gn/T/ipykernel_72104/2531528777.py\", line 23, in forward\n",
      "    X, (h, c )= self.lstm(X,( h, c))\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    if a single value is returned(unless that value is already a tuple).\n",
      "  File \"/Users/doriclink/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/rnn.py\", line 772, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      " (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "30:44/143 Loss:2.658299684524536:  50%|█████     | 10/20 [17:08<17:08, 102.82s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'MpsLinearBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [247], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m# print(\"PREDS\",preds.shape)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(preds\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m), tgt\u001b[39m.\u001b[39mlong(), ignore_index\u001b[39m=\u001b[39m\u001b[39m26\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnamed_parameters():\n\u001b[1;32m     26\u001b[0m     param\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mclamp(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'MpsLinearBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(33)\n",
    "num_epochs = 20\n",
    "device = torch.device(\"mps\")\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "model = Gen(n_chars, 256, n_chars, total_lens, 2, 0.5, device)\n",
    "model.load_state_dict(torch.load(\"./weights/gen_weights_2_29.pt\"))\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "for ep in (pbar:=tqdm(range(num_epochs))):\n",
    "    for idx, (src, lens, tgt) in enumerate(loader):\n",
    "        # print(src[:3])\n",
    "        # print(tgt[:3])\n",
    "        # print(lens)\n",
    "        optim.zero_grad()\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        # print(\"SRC\", src.shape)\n",
    "        h, c = model.init_hidden(bs)\n",
    "        preds, h, c = model(src, lens, h, c)\n",
    "        # print(\"PREDS\",preds.shape)\n",
    "        loss = F.cross_entropy(preds.permute(0,2,1), tgt.long(), ignore_index=26)\n",
    "        loss.backward()\n",
    "        for name, param in model.named_parameters():\n",
    "            param.grad.clamp(-1,1)\n",
    "        optim.step()\n",
    "        pbar.set_description(f\"{ep+20}:{idx}/{len(loader)} Loss:{loss.item()}\")\n",
    "        if (ep+1) %5 == 0:\n",
    "            torch.save(model.state_dict(), f\"./weights/gen_weights_3_{ep+20}.pt\")\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e*a\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./weights/gen_weights_2_29.pt\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "out = model.generate(\"e\", 2)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
